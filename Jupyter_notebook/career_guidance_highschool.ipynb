{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84ea8660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb8f3201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>gender</th>\n",
       "      <th>part_time_job</th>\n",
       "      <th>absence_days</th>\n",
       "      <th>extracurricular_activities</th>\n",
       "      <th>weekly_self_study_hours</th>\n",
       "      <th>career_aspiration</th>\n",
       "      <th>math_score</th>\n",
       "      <th>history_score</th>\n",
       "      <th>physics_score</th>\n",
       "      <th>chemistry_score</th>\n",
       "      <th>biology_score</th>\n",
       "      <th>english_score</th>\n",
       "      <th>geography_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Paul</td>\n",
       "      <td>Casey</td>\n",
       "      <td>paul.casey.1@gslingacademy.com</td>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>73</td>\n",
       "      <td>81</td>\n",
       "      <td>93</td>\n",
       "      <td>97</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Danielle</td>\n",
       "      <td>Sandoval</td>\n",
       "      <td>danielle.sandoval.2@gslingacademy.com</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>47</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tina</td>\n",
       "      <td>Andrews</td>\n",
       "      <td>tina.andrews.3@gslingacademy.com</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>Government Officer</td>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>65</td>\n",
       "      <td>77</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Tara</td>\n",
       "      <td>Clark</td>\n",
       "      <td>tara.clark.4@gslingacademy.com</td>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>Artist</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "      <td>63</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Anthony</td>\n",
       "      <td>Campos</td>\n",
       "      <td>anthony.campos.5@gslingacademy.com</td>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id first_name last_name                                  email  gender  \\\n",
       "0   1       Paul     Casey         paul.casey.1@gslingacademy.com    male   \n",
       "1   2   Danielle  Sandoval  danielle.sandoval.2@gslingacademy.com  female   \n",
       "2   3       Tina   Andrews       tina.andrews.3@gslingacademy.com  female   \n",
       "3   4       Tara     Clark         tara.clark.4@gslingacademy.com  female   \n",
       "4   5    Anthony    Campos     anthony.campos.5@gslingacademy.com    male   \n",
       "\n",
       "   part_time_job  absence_days  extracurricular_activities  \\\n",
       "0          False             3                       False   \n",
       "1          False             2                       False   \n",
       "2          False             9                        True   \n",
       "3          False             5                       False   \n",
       "4          False             5                       False   \n",
       "\n",
       "   weekly_self_study_hours   career_aspiration  math_score  history_score  \\\n",
       "0                       27              Lawyer          73             81   \n",
       "1                       47              Doctor          90             86   \n",
       "2                       13  Government Officer          81             97   \n",
       "3                        3              Artist          71             74   \n",
       "4                       10             Unknown          84             77   \n",
       "\n",
       "   physics_score  chemistry_score  biology_score  english_score  \\\n",
       "0             93               97             63             80   \n",
       "1             96              100             90             88   \n",
       "2             95               96             65             77   \n",
       "3             88               80             89             63   \n",
       "4             65               65             80             74   \n",
       "\n",
       "   geography_score  \n",
       "0               87  \n",
       "1               90  \n",
       "2               94  \n",
       "3               86  \n",
       "4               76  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\joelf\\Desktop\\student-scores.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a31af45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['id','first_name','last_name','email'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b3f1b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>part_time_job</th>\n",
       "      <th>absence_days</th>\n",
       "      <th>extracurricular_activities</th>\n",
       "      <th>weekly_self_study_hours</th>\n",
       "      <th>career_aspiration</th>\n",
       "      <th>math_score</th>\n",
       "      <th>history_score</th>\n",
       "      <th>physics_score</th>\n",
       "      <th>chemistry_score</th>\n",
       "      <th>biology_score</th>\n",
       "      <th>english_score</th>\n",
       "      <th>geography_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>73</td>\n",
       "      <td>81</td>\n",
       "      <td>93</td>\n",
       "      <td>97</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>47</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>Government Officer</td>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>65</td>\n",
       "      <td>77</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>Artist</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "      <td>63</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  part_time_job  absence_days  extracurricular_activities  \\\n",
       "0    male          False             3                       False   \n",
       "1  female          False             2                       False   \n",
       "2  female          False             9                        True   \n",
       "3  female          False             5                       False   \n",
       "4    male          False             5                       False   \n",
       "\n",
       "   weekly_self_study_hours   career_aspiration  math_score  history_score  \\\n",
       "0                       27              Lawyer          73             81   \n",
       "1                       47              Doctor          90             86   \n",
       "2                       13  Government Officer          81             97   \n",
       "3                        3              Artist          71             74   \n",
       "4                       10             Unknown          84             77   \n",
       "\n",
       "   physics_score  chemistry_score  biology_score  english_score  \\\n",
       "0             93               97             63             80   \n",
       "1             96              100             90             88   \n",
       "2             95               96             65             77   \n",
       "3             88               80             89             63   \n",
       "4             65               65             80             74   \n",
       "\n",
       "   geography_score  \n",
       "0               87  \n",
       "1               90  \n",
       "2               94  \n",
       "3               86  \n",
       "4               76  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "720c3b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>part_time_job</th>\n",
       "      <th>absence_days</th>\n",
       "      <th>extracurricular_activities</th>\n",
       "      <th>weekly_self_study_hours</th>\n",
       "      <th>career_aspiration</th>\n",
       "      <th>math_score</th>\n",
       "      <th>history_score</th>\n",
       "      <th>physics_score</th>\n",
       "      <th>chemistry_score</th>\n",
       "      <th>biology_score</th>\n",
       "      <th>english_score</th>\n",
       "      <th>geography_score</th>\n",
       "      <th>total_score</th>\n",
       "      <th>average_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>27</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>73</td>\n",
       "      <td>81</td>\n",
       "      <td>93</td>\n",
       "      <td>97</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>574</td>\n",
       "      <td>82.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>47</td>\n",
       "      <td>Doctor</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>90</td>\n",
       "      <td>640</td>\n",
       "      <td>91.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>Government Officer</td>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>65</td>\n",
       "      <td>77</td>\n",
       "      <td>94</td>\n",
       "      <td>605</td>\n",
       "      <td>86.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>Artist</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "      <td>63</td>\n",
       "      <td>86</td>\n",
       "      <td>551</td>\n",
       "      <td>78.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>10</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "      <td>521</td>\n",
       "      <td>74.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  part_time_job  absence_days  extracurricular_activities  \\\n",
       "0    male          False             3                       False   \n",
       "1  female          False             2                       False   \n",
       "2  female          False             9                        True   \n",
       "3  female          False             5                       False   \n",
       "4    male          False             5                       False   \n",
       "\n",
       "   weekly_self_study_hours   career_aspiration  math_score  history_score  \\\n",
       "0                       27              Lawyer          73             81   \n",
       "1                       47              Doctor          90             86   \n",
       "2                       13  Government Officer          81             97   \n",
       "3                        3              Artist          71             74   \n",
       "4                       10             Unknown          84             77   \n",
       "\n",
       "   physics_score  chemistry_score  biology_score  english_score  \\\n",
       "0             93               97             63             80   \n",
       "1             96              100             90             88   \n",
       "2             95               96             65             77   \n",
       "3             88               80             89             63   \n",
       "4             65               65             80             74   \n",
       "\n",
       "   geography_score  total_score  average_score  \n",
       "0               87          574      82.000000  \n",
       "1               90          640      91.428571  \n",
       "2               94          605      86.428571  \n",
       "3               86          551      78.714286  \n",
       "4               76          521      74.428571  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"total_score\"] = df[\"math_score\"] + df[\"history_score\"] + df[\"physics_score\"] + df[\"chemistry_score\"] + df[\"biology_score\"] + df[\"english_score\"] + df[\"geography_score\"]\n",
    "df[\"average_score\"] = df[\"total_score\"] / 7\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42453ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 15)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "397dcbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_map = {'male': 0, 'female': 1}\n",
    "part_time_job_map = {False: 0, True: 1}\n",
    "extracurricular_activities_map = {False: 0, True: 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db7fb88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "career_aspiration_map = {\n",
    "        'Lawyer': 0, 'Doctor': 1, 'Government Officer': 2, 'Artist': 3, 'Unknown': 4,\n",
    "        'Software Engineer': 5, 'Teacher': 6, 'Business Owner': 7, 'Scientist': 8,\n",
    "        'Banker': 9, 'Writer': 10, 'Accountant': 11, 'Designer': 12,\n",
    "        'Construction Engineer': 13, 'Game Developer': 14, 'Stock Investor': 15,\n",
    "        'Real Estate Developer': 16\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "092cb79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'] = df['gender'].map(gender_map)\n",
    "df['part_time_job'] = df['part_time_job'].map(part_time_job_map)\n",
    "df['extracurricular_activities'] = df['extracurricular_activities'].map(extracurricular_activities_map)\n",
    "df['career_aspiration'] = df['career_aspiration'].map(career_aspiration_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1323e40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>part_time_job</th>\n",
       "      <th>absence_days</th>\n",
       "      <th>extracurricular_activities</th>\n",
       "      <th>weekly_self_study_hours</th>\n",
       "      <th>career_aspiration</th>\n",
       "      <th>math_score</th>\n",
       "      <th>history_score</th>\n",
       "      <th>physics_score</th>\n",
       "      <th>chemistry_score</th>\n",
       "      <th>biology_score</th>\n",
       "      <th>english_score</th>\n",
       "      <th>geography_score</th>\n",
       "      <th>total_score</th>\n",
       "      <th>average_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>81</td>\n",
       "      <td>93</td>\n",
       "      <td>97</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>574</td>\n",
       "      <td>82.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>86</td>\n",
       "      <td>96</td>\n",
       "      <td>100</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>90</td>\n",
       "      <td>640</td>\n",
       "      <td>91.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>96</td>\n",
       "      <td>65</td>\n",
       "      <td>77</td>\n",
       "      <td>94</td>\n",
       "      <td>605</td>\n",
       "      <td>86.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>71</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "      <td>80</td>\n",
       "      <td>89</td>\n",
       "      <td>63</td>\n",
       "      <td>86</td>\n",
       "      <td>551</td>\n",
       "      <td>78.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>84</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "      <td>521</td>\n",
       "      <td>74.428571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  part_time_job  absence_days  extracurricular_activities  \\\n",
       "0       0              0             3                           0   \n",
       "1       1              0             2                           0   \n",
       "2       1              0             9                           1   \n",
       "3       1              0             5                           0   \n",
       "4       0              0             5                           0   \n",
       "\n",
       "   weekly_self_study_hours  career_aspiration  math_score  history_score  \\\n",
       "0                       27                  0          73             81   \n",
       "1                       47                  1          90             86   \n",
       "2                       13                  2          81             97   \n",
       "3                        3                  3          71             74   \n",
       "4                       10                  4          84             77   \n",
       "\n",
       "   physics_score  chemistry_score  biology_score  english_score  \\\n",
       "0             93               97             63             80   \n",
       "1             96              100             90             88   \n",
       "2             95               96             65             77   \n",
       "3             88               80             89             63   \n",
       "4             65               65             80             74   \n",
       "\n",
       "   geography_score  total_score  average_score  \n",
       "0               87          574      82.000000  \n",
       "1               90          640      91.428571  \n",
       "2               94          605      86.428571  \n",
       "3               86          551      78.714286  \n",
       "4               76          521      74.428571  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aacf6822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                          int64\n",
       "part_time_job                   int64\n",
       "absence_days                    int64\n",
       "extracurricular_activities      int64\n",
       "weekly_self_study_hours         int64\n",
       "career_aspiration               int64\n",
       "math_score                      int64\n",
       "history_score                   int64\n",
       "physics_score                   int64\n",
       "chemistry_score                 int64\n",
       "biology_score                   int64\n",
       "english_score                   int64\n",
       "geography_score                 int64\n",
       "total_score                     int64\n",
       "average_score                 float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9795274d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "career_aspiration\n",
       "5     315\n",
       "7     309\n",
       "4     223\n",
       "9     169\n",
       "0     138\n",
       "11    126\n",
       "1     119\n",
       "16     83\n",
       "15     73\n",
       "13     68\n",
       "3      67\n",
       "14     63\n",
       "2      61\n",
       "6      59\n",
       "12     56\n",
       "8      39\n",
       "10     32\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data is imbalance\n",
    "df[\"career_aspiration\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271fdd01",
   "metadata": {},
   "source": [
    "# Balancing the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c453ca13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use SMOTE library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24ad35eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Create SMOTE object\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df.drop('career_aspiration', axis=1)\n",
    "y = df['career_aspiration']\n",
    "\n",
    "# Apply SMOTE to the data\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bea0cb6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "career_aspiration\n",
       "0     315\n",
       "9     315\n",
       "15    315\n",
       "14    315\n",
       "13    315\n",
       "12    315\n",
       "11    315\n",
       "10    315\n",
       "8     315\n",
       "1     315\n",
       "7     315\n",
       "6     315\n",
       "5     315\n",
       "4     315\n",
       "3     315\n",
       "2     315\n",
       "16    315\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "980b71e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_resampled,y_resampled,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaa621d",
   "metadata": {},
   "source": [
    "# Feature_Scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ab941c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data and transform both training and testing data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20eeecf",
   "metadata": {},
   "source": [
    "# Traning with multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b76880f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.48739495798319327\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.54      0.49        68\n",
      "           1       0.49      0.62      0.55        72\n",
      "           2       0.42      0.44      0.43        57\n",
      "           3       0.52      0.57      0.55        58\n",
      "           4       0.31      0.17      0.22        66\n",
      "           5       0.32      0.32      0.32        76\n",
      "           6       0.58      0.92      0.71        71\n",
      "           7       0.83      0.90      0.87        61\n",
      "           8       0.41      0.45      0.43        53\n",
      "           9       0.29      0.10      0.15        61\n",
      "          10       0.59      0.71      0.65        63\n",
      "          11       0.44      0.45      0.45        53\n",
      "          12       0.31      0.16      0.21        68\n",
      "          13       0.38      0.49      0.43        55\n",
      "          14       0.61      0.93      0.74        57\n",
      "          15       0.37      0.24      0.29        63\n",
      "          16       0.55      0.32      0.40        69\n",
      "\n",
      "    accuracy                           0.49      1071\n",
      "   macro avg       0.46      0.49      0.46      1071\n",
      "weighted avg       0.46      0.49      0.46      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[37  4  0  0  0  7  0  0  4  1 10  3  0  2  0  0  0]\n",
      " [ 2 45  0  0  0  7  0  0 13  0  0  0  0  5  0  0  0]\n",
      " [ 0  0 25  5  1  1  9  1  0  0  2  0  4  1  2  2  4]\n",
      " [ 0  0  2 33  0  0  2  1  0  0  0  0  0  0 11  0  9]\n",
      " [ 6  5  7  3 11  9  7  1  2  3  0  3  3  2  1  2  1]\n",
      " [ 8  9  0  0  1 24  1  0  1  7  1  5  3 12  0  4  0]\n",
      " [ 0  0  0  0  1  2 65  0  0  1  2  0  0  0  0  0  0]\n",
      " [ 0  0  0  3  0  0  0 55  0  0  0  0  0  0  3  0  0]\n",
      " [ 4 18  0  0  0  1  0  0 24  0  6  0  0  0  0  0  0]\n",
      " [10  1  0  0  3  8  8  0  1  6  2  8  6  6  0  2  0]\n",
      " [ 8  2  0  0  1  0  4  0  2  1 45  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  4  6  3  0  4  1  0 24  1  3  0  6  0]\n",
      " [ 2  2  8  3  5  2  7  0  3  0  4  0 11  6  8  5  2]\n",
      " [ 1  2  2  0  3  0  0  0  5  1  1  4  4 27  0  5  0]\n",
      " [ 0  0  0  3  0  0  0  0  0  0  0  0  0  0 53  0  1]\n",
      " [ 4  3  3  0  5  8  1  2  0  0  2  7  4  7  1 15  1]\n",
      " [ 0  0 13 13  0  1  5  6  0  0  1  0  0  0  8  0 22]]\n",
      "==================================================\n",
      "Model: Support Vector Classifier\n",
      "Accuracy: 0.6470588235294118\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.62      0.58        68\n",
      "           1       0.60      0.83      0.70        72\n",
      "           2       0.60      0.74      0.66        57\n",
      "           3       0.69      0.86      0.77        58\n",
      "           4       0.55      0.18      0.27        66\n",
      "           5       0.41      0.32      0.36        76\n",
      "           6       0.70      0.93      0.80        71\n",
      "           7       0.86      0.93      0.90        61\n",
      "           8       0.65      0.81      0.72        53\n",
      "           9       0.38      0.33      0.35        61\n",
      "          10       0.84      0.86      0.85        63\n",
      "          11       0.82      0.51      0.63        53\n",
      "          12       0.65      0.51      0.57        68\n",
      "          13       0.53      0.85      0.65        55\n",
      "          14       0.77      0.93      0.84        57\n",
      "          15       0.67      0.44      0.53        63\n",
      "          16       0.77      0.48      0.59        69\n",
      "\n",
      "    accuracy                           0.65      1071\n",
      "   macro avg       0.65      0.66      0.63      1071\n",
      "weighted avg       0.65      0.65      0.63      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[42  6  0  0  0  4  0  0  2  4  6  0  0  3  0  1  0]\n",
      " [ 1 60  0  0  0  1  0  0  5  0  0  0  1  3  0  1  0]\n",
      " [ 0  0 42  2  2  1  4  0  0  0  0  0  2  0  0  3  1]\n",
      " [ 0  0  2 50  0  0  0  1  0  0  0  0  0  0  3  0  2]\n",
      " [ 5  8  7  1 12  7  5  2  1  7  0  2  4  3  1  1  0]\n",
      " [10  7  1  0  1 24  1  1  5 12  0  1  1 11  0  1  0]\n",
      " [ 0  0  0  0  0  1 66  0  0  2  1  0  0  0  0  0  1]\n",
      " [ 0  0  0  1  0  0  1 57  0  0  0  0  0  0  1  0  1]\n",
      " [ 1  8  0  0  0  1  0  0 43  0  0  0  0  0  0  0  0]\n",
      " [ 8  1  1  0  0  7  6  1  3 20  1  0  4  5  0  4  0]\n",
      " [ 2  1  4  0  0  0  0  0  0  1 54  0  0  1  0  0  0]\n",
      " [ 0  3  1  0  3  5  0  1  3  2  1 27  1  3  0  3  0]\n",
      " [ 2  1  0  3  2  1  8  0  2  0  1  1 35  4  4  0  4]\n",
      " [ 0  3  0  0  0  1  0  0  2  1  0  1  0 47  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  2  0  0  0  0  1  0 53  0  0]\n",
      " [ 5  2  3  0  2  4  0  0  0  3  0  1  4  9  1 28  1]\n",
      " [ 0  0  9 15  0  2  2  1  0  0  0  0  1  0  6  0 33]]\n",
      "==================================================\n",
      "Model: Random Forest Classifier\n",
      "Accuracy: 0.8431372549019608\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83        68\n",
      "           1       0.81      0.99      0.89        72\n",
      "           2       0.73      0.96      0.83        57\n",
      "           3       0.89      0.95      0.92        58\n",
      "           4       0.78      0.44      0.56        66\n",
      "           5       0.62      0.43      0.51        76\n",
      "           6       0.96      1.00      0.98        71\n",
      "           7       0.97      0.97      0.97        61\n",
      "           8       0.73      0.98      0.84        53\n",
      "           9       0.76      0.79      0.77        61\n",
      "          10       0.94      0.97      0.95        63\n",
      "          11       0.91      0.75      0.82        53\n",
      "          12       0.94      0.88      0.91        68\n",
      "          13       0.77      0.91      0.83        55\n",
      "          14       0.92      1.00      0.96        57\n",
      "          15       0.88      0.78      0.82        63\n",
      "          16       0.93      0.80      0.86        69\n",
      "\n",
      "    accuracy                           0.84      1071\n",
      "   macro avg       0.84      0.85      0.84      1071\n",
      "weighted avg       0.84      0.84      0.84      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[58  4  0  0  1  2  0  0  0  1  1  0  0  0  0  1  0]\n",
      " [ 0 71  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 55  0  0  0  1  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0 55  0  0  0  1  0  0  0  0  0  0  2  0  0]\n",
      " [ 4  3  8  0 29  8  0  0  2  3  1  2  2  0  1  1  2]\n",
      " [ 6  4  0  0  3 33  0  0  7  8  0  2  2  9  0  2  0]\n",
      " [ 0  0  0  0  0  0 71  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0 59  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  1  0  0  0  0  0  0 52  0  0  0  0  0  0  0  0]\n",
      " [ 2  1  1  0  0  3  1  0  2 48  1  0  0  0  0  2  0]\n",
      " [ 0  0  2  0  0  0  0  0  0  0 61  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  2  4  0  0  3  1  0 40  0  1  0  0  0]\n",
      " [ 0  0  2  0  1  0  1  0  1  0  1  0 60  0  1  0  1]\n",
      " [ 0  0  2  0  0  0  0  0  2  0  0  0  0 50  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 57  0  0]\n",
      " [ 2  2  2  0  0  2  0  0  0  1  0  0  0  5  0 49  0]\n",
      " [ 0  0  3  6  1  1  0  1  1  1  0  0  0  0  0  0 55]]\n",
      "==================================================\n",
      "Model: K Nearest Neighbors\n",
      "Accuracy: 0.6778711484593838\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.68      0.63        68\n",
      "           1       0.73      0.78      0.75        72\n",
      "           2       0.63      0.86      0.73        57\n",
      "           3       0.60      0.81      0.69        58\n",
      "           4       0.35      0.17      0.23        66\n",
      "           5       0.35      0.14      0.21        76\n",
      "           6       0.83      0.92      0.87        71\n",
      "           7       0.90      0.72      0.80        61\n",
      "           8       0.67      0.91      0.77        53\n",
      "           9       0.44      0.48      0.46        61\n",
      "          10       0.81      0.92      0.86        63\n",
      "          11       0.71      0.64      0.67        53\n",
      "          12       0.71      0.79      0.75        68\n",
      "          13       0.69      0.80      0.74        55\n",
      "          14       0.82      0.89      0.86        57\n",
      "          15       0.65      0.62      0.63        63\n",
      "          16       0.78      0.58      0.67        69\n",
      "\n",
      "    accuracy                           0.68      1071\n",
      "   macro avg       0.66      0.69      0.67      1071\n",
      "weighted avg       0.66      0.68      0.66      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[46  2  0  0  0  3  0  0  1  8  6  0  0  0  0  2  0]\n",
      " [ 4 56  0  0  1  0  0  0  4  1  1  0  1  1  0  3  0]\n",
      " [ 0  0 49  1  0  0  0  0  0  0  2  0  0  0  1  1  3]\n",
      " [ 0  0  4 47  0  0  0  1  0  1  0  0  0  0  3  0  2]\n",
      " [ 4  5  5  5 11  6  6  1  2  7  1  1  6  1  1  1  3]\n",
      " [10  6  2  0  7 11  1  1  6  9  0  3  6 10  0  4  0]\n",
      " [ 0  0  1  2  0  0 65  0  0  2  0  0  0  0  1  0  0]\n",
      " [ 0  0  1  3  2  0  1 44  0  2  0  1  2  1  1  1  2]\n",
      " [ 1  4  0  0  0  0  0  0 48  0  0  0  0  0  0  0  0]\n",
      " [ 6  0  2  1  3  3  1  1  2 29  1  4  4  0  0  3  1]\n",
      " [ 2  0  2  0  0  0  0  0  0  1 58  0  0  0  0  0  0]\n",
      " [ 0  2  2  0  0  5  0  0  3  2  1 34  1  2  1  0  0]\n",
      " [ 1  1  2  2  0  0  1  0  0  2  1  1 54  0  0  3  0]\n",
      " [ 2  0  0  0  4  0  0  0  3  0  0  0  0 44  1  1  0]\n",
      " [ 0  0  1  1  0  1  0  0  0  0  0  0  1  1 51  1  0]\n",
      " [ 2  1  1  4  2  1  1  0  3  2  0  4  0  3  0 39  0]\n",
      " [ 0  0  6 12  1  1  2  1  0  0  1  0  1  1  2  1 40]]\n",
      "==================================================\n",
      "Model: Decision Tree Classifier\n",
      "Accuracy: 0.680672268907563\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.62      0.61        68\n",
      "           1       0.79      0.86      0.83        72\n",
      "           2       0.69      0.74      0.71        57\n",
      "           3       0.81      0.76      0.79        58\n",
      "           4       0.41      0.36      0.38        66\n",
      "           5       0.40      0.22      0.29        76\n",
      "           6       0.86      0.85      0.85        71\n",
      "           7       0.94      0.75      0.84        61\n",
      "           8       0.78      0.89      0.83        53\n",
      "           9       0.45      0.56      0.50        61\n",
      "          10       0.81      0.83      0.82        63\n",
      "          11       0.55      0.64      0.59        53\n",
      "          12       0.68      0.74      0.71        68\n",
      "          13       0.62      0.75      0.68        55\n",
      "          14       0.83      0.91      0.87        57\n",
      "          15       0.54      0.49      0.52        63\n",
      "          16       0.74      0.74      0.74        69\n",
      "\n",
      "    accuracy                           0.68      1071\n",
      "   macro avg       0.68      0.69      0.68      1071\n",
      "weighted avg       0.68      0.68      0.67      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[42  3  0  0  2  5  0  0  1  2  3  5  2  1  0  2  0]\n",
      " [ 2 62  0  0  1  2  0  0  2  3  0  0  0  0  0  0  0]\n",
      " [ 0  0 42  1  1  1  0  0  0  2  0  0  3  1  0  2  4]\n",
      " [ 0  0  2 44  2  0  0  1  0  0  0  0  1  0  4  0  4]\n",
      " [ 3  2  5  0 24  3  3  1  2  6  3  3  2  1  1  2  5]\n",
      " [10  5  0  0  7 17  1  0  3 10  1  5  3  7  0  7  0]\n",
      " [ 0  0  1  0  2  2 60  0  0  3  1  0  2  0  0  0  0]\n",
      " [ 0  0  0  3  4  0  0 46  0  0  0  0  1  0  4  0  3]\n",
      " [ 2  0  0  0  0  0  0  0 47  1  1  2  0  0  0  0  0]\n",
      " [ 7  0  0  0  1  2  2  0  2 34  2  3  2  1  0  4  1]\n",
      " [ 0  1  1  0  0  1  0  0  1  4 52  0  1  1  0  1  0]\n",
      " [ 0  2  0  0  3  1  3  0  2  1  0 34  3  2  0  2  0]\n",
      " [ 0  1  2  1  4  1  1  0  0  3  0  1 50  2  1  1  0]\n",
      " [ 2  1  1  0  1  0  0  0  0  2  1  3  0 41  0  3  0]\n",
      " [ 0  0  0  1  1  0  0  0  0  0  0  0  2  0 52  0  1]\n",
      " [ 1  1  3  0  2  6  0  0  0  3  0  6  1  9  0 31  0]\n",
      " [ 0  0  4  4  4  1  0  1  0  1  0  0  0  0  1  2 51]]\n",
      "==================================================\n",
      "Model: Gaussian Naive Bayes\n",
      "Accuracy: 0.3099906629318394\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.22      0.32        68\n",
      "           1       0.64      0.53      0.58        72\n",
      "           2       0.18      0.05      0.08        57\n",
      "           3       0.30      0.05      0.09        58\n",
      "           4       0.50      0.06      0.11        66\n",
      "           5       0.45      0.18      0.26        76\n",
      "           6       0.31      1.00      0.47        71\n",
      "           7       0.95      0.85      0.90        61\n",
      "           8       0.64      0.17      0.27        53\n",
      "           9       0.20      0.03      0.06        61\n",
      "          10       0.69      0.35      0.46        63\n",
      "          11       0.60      0.23      0.33        53\n",
      "          12       0.50      0.13      0.21        68\n",
      "          13       0.11      0.96      0.20        55\n",
      "          14       0.00      0.00      0.00        57\n",
      "          15       0.50      0.06      0.11        63\n",
      "          16       0.47      0.30      0.37        69\n",
      "\n",
      "    accuracy                           0.31      1071\n",
      "   macro avg       0.45      0.31      0.28      1071\n",
      "weighted avg       0.45      0.31      0.29      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[15  0  0  0  0  3  4  0  1  0  4  2  0 39  0  0  0]\n",
      " [ 0 38  0  0  0  2  3  0  3  0  0  0  2 24  0  0  0]\n",
      " [ 0  0  3  0  1  1 16  0  0  0  0  0  0 31  0  2  3]\n",
      " [ 0  0  0  3  0  0 15  1  0  0  0  0  0 23  3  0 13]\n",
      " [ 3  3  0  3  4  3 13  0  0  2  0  3  3 26  0  0  3]\n",
      " [ 4  6  0  0  1 14 12  0  0  2  0  1  1 34  0  1  0]\n",
      " [ 0  0  0  0  0  0 71  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  3 52  0  0  0  0  0  3  0  0  2]\n",
      " [ 0  3  0  0  0  0  0  0  9  1  1  0  0 39  0  0  0]\n",
      " [ 2  1  1  0  1  2 16  0  0  2  4  1  1 30  0  0  0]\n",
      " [ 3  6  0  0  0  0  9  0  0  1 22  0  0 22  0  0  0]\n",
      " [ 0  0  0  0  0  1 13  0  0  0  0 12  1 25  0  1  0]\n",
      " [ 0  1  7  0  0  0 21  0  1  0  1  0  9 27  0  0  1]\n",
      " [ 0  1  0  0  0  1  0  0  0  0  0  0  0 53  0  0  0]\n",
      " [ 0  0  0  0  0  0 11  1  0  0  0  0  0 45  0  0  0]\n",
      " [ 0  0  1  0  1  2  6  0  0  1  0  1  1 44  0  4  2]\n",
      " [ 0  0  5  3  0  2 16  1  0  1  0  0  0 20  0  0 21]]\n",
      "==================================================\n",
      "Model: AdaBoost Classifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2334267040149393\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        68\n",
      "           1       1.00      0.61      0.76        72\n",
      "           2       0.28      0.56      0.37        57\n",
      "           3       0.00      0.00      0.00        58\n",
      "           4       0.00      0.00      0.00        66\n",
      "           5       0.00      0.00      0.00        76\n",
      "           6       0.29      0.79      0.42        71\n",
      "           7       0.00      0.00      0.00        61\n",
      "           8       0.15      1.00      0.27        53\n",
      "           9       0.00      0.00      0.00        61\n",
      "          10       0.18      0.38      0.25        63\n",
      "          11       0.00      0.00      0.00        53\n",
      "          12       0.00      0.00      0.00        68\n",
      "          13       0.00      0.00      0.00        55\n",
      "          14       0.00      0.00      0.00        57\n",
      "          15       0.00      0.00      0.00        63\n",
      "          16       0.17      0.59      0.27        69\n",
      "\n",
      "    accuracy                           0.23      1071\n",
      "   macro avg       0.12      0.23      0.14      1071\n",
      "weighted avg       0.13      0.23      0.14      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 0  0  0  0  0  0  0  0 68  0  0  0  0  0  0  0  0]\n",
      " [ 0 44  0  0  0  0  0  0 20  0  8  0  0  0  0  0  0]\n",
      " [ 0  0 32  0  0  0 15  0  0  0  0  0  0  0  0  0 10]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 58]\n",
      " [ 0  0 14  0  0  0  9  0 27  0 11  0  0  0  0  0  5]\n",
      " [ 0  0  0  0  0  0 10  0 45  0 21  0  0  0  0  0  0]\n",
      " [ 0  0 14  0  0  0 56  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 61]\n",
      " [ 0  0  0  0  0  0  0  0 53  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  3  0  0  0 18  0 24  0 16  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  8  0 31  0 24  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 15  0 22  0 16  0  0  0  0  0  0]\n",
      " [ 0  0 16  0  0  0 24  0 12  0  8  0  0  0  0  0  8]\n",
      " [ 0  0  1  0  0  0 25  0 14  0 15  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 57]\n",
      " [ 0  0  8  0  0  0 15  0 28  0 12  0  0  0  0  0  0]\n",
      " [ 0  0 28  0  0  0  0  0  0  0  0  0  0  0  0  0 41]]\n",
      "==================================================\n",
      "Model: Gradient Boosting Classifier\n",
      "Accuracy: 0.746031746031746\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.79      0.73        68\n",
      "           1       0.79      0.97      0.87        72\n",
      "           2       0.63      0.88      0.74        57\n",
      "           3       0.81      0.90      0.85        58\n",
      "           4       0.48      0.15      0.23        66\n",
      "           5       0.50      0.46      0.48        76\n",
      "           6       0.85      0.99      0.92        71\n",
      "           7       0.97      0.95      0.96        61\n",
      "           8       0.78      0.98      0.87        53\n",
      "           9       0.49      0.44      0.47        61\n",
      "          10       0.90      0.95      0.92        63\n",
      "          11       0.80      0.62      0.70        53\n",
      "          12       0.76      0.60      0.67        68\n",
      "          13       0.65      0.87      0.74        55\n",
      "          14       0.89      0.98      0.93        57\n",
      "          15       0.75      0.57      0.65        63\n",
      "          16       0.82      0.68      0.75        69\n",
      "\n",
      "    accuracy                           0.75      1071\n",
      "   macro avg       0.74      0.75      0.73      1071\n",
      "weighted avg       0.73      0.75      0.73      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[54  4  0  0  2  5  0  0  0  1  0  2  0  0  0  0  0]\n",
      " [ 1 70  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0 50  1  0  1  3  0  0  0  0  0  0  0  0  0  2]\n",
      " [ 0  0  0 52  0  0  0  1  0  0  0  0  1  0  2  0  2]\n",
      " [ 5  4 11  0 10 10  1  0  1  8  2  1  3  4  1  3  2]\n",
      " [ 7  3  0  0  1 35  0  0  3 11  0  1  0 12  0  3  0]\n",
      " [ 0  0  0  0  1  0 70  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  0  0  0 58  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  1  0  0  0  0  0  0 52  0  0  0  0  0  0  0  0]\n",
      " [ 5  0  3  0  2  5  3  0  4 27  3  0  4  1  0  4  0]\n",
      " [ 2  1  0  0  0  0  0  0  0  0 60  0  0  0  0  0  0]\n",
      " [ 1  3  1  0  1  3  2  0  3  4  0 33  0  2  0  0  0]\n",
      " [ 1  0  5  1  1  3  1  0  1  3  1  1 41  2  2  2  3]\n",
      " [ 1  1  2  0  0  1  0  0  2  0  0  0  0 48  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0 56  0  0]\n",
      " [ 3  2  2  0  1  7  0  0  1  1  1  3  1  4  0 36  1]\n",
      " [ 0  0  5  8  2  0  2  1  0  0  0  0  3  0  1  0 47]]\n",
      "==================================================\n",
      "Model: XGBoost Classifier\n",
      "Accuracy: 0.8272642390289449\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.82        68\n",
      "           1       0.83      0.94      0.88        72\n",
      "           2       0.81      0.91      0.86        57\n",
      "           3       0.87      0.91      0.89        58\n",
      "           4       0.88      0.42      0.57        66\n",
      "           5       0.55      0.42      0.48        76\n",
      "           6       0.92      0.97      0.95        71\n",
      "           7       0.95      0.93      0.94        61\n",
      "           8       0.84      1.00      0.91        53\n",
      "           9       0.61      0.70      0.66        61\n",
      "          10       0.98      0.97      0.98        63\n",
      "          11       0.75      0.72      0.73        53\n",
      "          12       0.91      0.93      0.92        68\n",
      "          13       0.75      0.91      0.82        55\n",
      "          14       0.92      0.98      0.95        57\n",
      "          15       0.78      0.71      0.74        63\n",
      "          16       0.94      0.87      0.90        69\n",
      "\n",
      "    accuracy                           0.83      1071\n",
      "   macro avg       0.83      0.83      0.82      1071\n",
      "weighted avg       0.83      0.83      0.82      1071\n",
      "\n",
      "Confusion Matrix:\n",
      " [[58  3  0  0  2  1  0  0  0  1  0  1  0  1  0  1  0]\n",
      " [ 1 68  0  0  0  0  0  0  1  1  0  0  1  0  0  0  0]\n",
      " [ 0  0 52  0  0  1  1  0  0  1  0  0  1  0  0  0  1]\n",
      " [ 0  0  0 53  0  0  0  1  0  0  0  0  0  0  2  0  2]\n",
      " [ 4  3  6  0 28  9  2  0  2  6  1  0  2  0  1  2  0]\n",
      " [ 8  4  0  0  0 32  0  0  2 10  0  4  0 11  0  5  0]\n",
      " [ 0  0  0  0  0  0 69  0  0  2  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  3  0  0  0 57  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0 53  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  2  0  0  4  1  0  2 43  0  3  2  0  0  3  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0 61  0  0  1  0  0  0]\n",
      " [ 1  2  0  0  0  4  2  0  2  3  0 38  0  1  0  0  0]\n",
      " [ 0  1  1  0  0  0  0  0  0  0  0  1 63  0  2  0  0]\n",
      " [ 0  0  1  0  0  2  0  0  0  0  0  0  0 50  0  2  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0  0  0  0 56  0  0]\n",
      " [ 1  1  0  0  1  5  0  0  0  3  0  4  0  3  0 45  0]\n",
      " [ 0  0  2  5  1  0  0  1  0  0  0  0  0  0  0  0 60]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Support Vector Classifier\": SVC(),\n",
    "    \"Random Forest Classifier\": RandomForestClassifier(),\n",
    "    \"K Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier(),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier(),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(),\n",
    "    \"XGBoost Classifier\": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(\"=\"*50)\n",
    "    print(\"Model:\", name)\n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\\n\", classification_rep)\n",
    "    print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12e0233a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8235294117647058\n",
      "Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79        68\n",
      "           1       0.78      0.99      0.87        72\n",
      "           2       0.72      0.96      0.83        57\n",
      "           3       0.86      0.95      0.90        58\n",
      "           4       0.85      0.42      0.57        66\n",
      "           5       0.60      0.36      0.45        76\n",
      "           6       0.92      0.99      0.95        71\n",
      "           7       0.97      0.92      0.94        61\n",
      "           8       0.75      0.98      0.85        53\n",
      "           9       0.65      0.69      0.67        61\n",
      "          10       0.90      0.98      0.94        63\n",
      "          11       0.89      0.75      0.82        53\n",
      "          12       0.92      0.84      0.88        68\n",
      "          13       0.75      0.89      0.82        55\n",
      "          14       0.89      1.00      0.94        57\n",
      "          15       0.89      0.78      0.83        63\n",
      "          16       0.93      0.81      0.87        69\n",
      "\n",
      "    accuracy                           0.82      1071\n",
      "   macro avg       0.83      0.83      0.82      1071\n",
      "weighted avg       0.82      0.82      0.81      1071\n",
      "\n",
      "Confusion Matrix:  [[56  5  0  0  1  2  0  0  0  2  1  0  0  0  0  1  0]\n",
      " [ 0 71  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 55  0  0  0  1  0  0  0  0  0  0  0  0  0  1]\n",
      " [ 0  0  0 55  0  0  0  1  0  0  0  0  0  0  2  0  0]\n",
      " [ 4  2  9  0 28  5  1  0  3  5  1  2  2  0  1  1  2]\n",
      " [ 9  8  0  0  0 27  1  0  4 13  1  1  0 11  0  1  0]\n",
      " [ 0  0  0  0  0  1 70  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  3  0  0  0 56  0  0  0  0  0  0  1  0  1]\n",
      " [ 0  1  0  0  0  0  0  0 52  0  0  0  0  0  0  0  0]\n",
      " [ 2  1  2  0  0  4  1  0  2 42  3  1  3  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0 62  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  2  4  1  0  2  1  0 40  0  1  0  0  0]\n",
      " [ 0  0  2  0  1  1  1  0  1  0  1  0 57  1  2  1  0]\n",
      " [ 0  0  2  0  0  0  0  0  2  0  0  0  0 49  0  2  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 57  0  0]\n",
      " [ 3  1  2  0  1  0  0  0  1  2  0  1  0  3  0 49  0]\n",
      " [ 0  0  4  6  0  0  0  1  1  0  0  0  0  0  1  0 56]]\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
    "print(\"Report: \",classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix: \",confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bd560d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# SAVE FILES\n",
    "pickle.dump(scaler,open(\"Models/scaler.pkl\",'wb'))\n",
    "pickle.dump(model,open(\"Models/model.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8a393ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load the scaler, label encoder, model, and class names\n",
    "scaler = pickle.load(open(\"Models/scaler.pkl\", 'rb'))\n",
    "model = pickle.load(open(\"Models/model.pkl\", 'rb'))\n",
    "class_names = ['Lawyer', 'Doctor', 'Government Officer', 'Artist', 'Unknown',\n",
    "               'Software Engineer', 'Teacher', 'Business Owner', 'Scientist',\n",
    "               'Banker', 'Writer', 'Accountant', 'Designer',\n",
    "               'Construction Engineer', 'Game Developer', 'Stock Investor',\n",
    "               'Real Estate Developer']\n",
    "\n",
    "def Recommendations(gender, part_time_job, absence_days, extracurricular_activities,\n",
    "                    weekly_self_study_hours, math_score, history_score, physics_score,\n",
    "                    chemistry_score, biology_score, english_score, geography_score):\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    gender_encoded = 1 if gender.lower() == 'female' else 0\n",
    "    part_time_job_encoded = 1 if part_time_job else 0\n",
    "    extracurricular_activities_encoded = 1 if extracurricular_activities else 0\n",
    "    \n",
    "    # Create feature array\n",
    "    feature_array = np.array([[gender_encoded, part_time_job_encoded, absence_days, extracurricular_activities_encoded,\n",
    "                               weekly_self_study_hours, math_score, history_score, physics_score,\n",
    "                               chemistry_score, biology_score, english_score, geography_score]])\n",
    "    \n",
    "    # Scale features\n",
    "    scaled_features = scaler.transform(feature_array)\n",
    "    \n",
    "    # Predict using the model\n",
    "    probabilities = model.predict(scaled_features)\n",
    "    return predicted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33f8c2f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 12 features, but StandardScaler is expecting 14 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m final_recommendations \u001b[38;5;241m=\u001b[39m Recommendations(gender\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfemale\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      2\u001b[0m                                         part_time_job\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m      3\u001b[0m                                         absence_days\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m      4\u001b[0m                                         extracurricular_activities\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m      5\u001b[0m                                         weekly_self_study_hours\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m,\n\u001b[0;32m      6\u001b[0m                                         math_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m65\u001b[39m,\n\u001b[0;32m      7\u001b[0m                                         history_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m60\u001b[39m,\n\u001b[0;32m      8\u001b[0m                                         physics_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m97\u001b[39m,\n\u001b[0;32m      9\u001b[0m                                         chemistry_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m94\u001b[39m,\n\u001b[0;32m     10\u001b[0m                                         biology_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m71\u001b[39m,\n\u001b[0;32m     11\u001b[0m                                         english_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m81\u001b[39m,\n\u001b[0;32m     12\u001b[0m                                         geography_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m66\u001b[39m)\n",
      "Cell \u001b[1;32mIn[22], line 28\u001b[0m, in \u001b[0;36mRecommendations\u001b[1;34m(gender, part_time_job, absence_days, extracurricular_activities, weekly_self_study_hours, math_score, history_score, physics_score, chemistry_score, biology_score, english_score, geography_score)\u001b[0m\n\u001b[0;32m     23\u001b[0m feature_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[gender_encoded, part_time_job_encoded, absence_days, extracurricular_activities_encoded,\n\u001b[0;32m     24\u001b[0m                            weekly_self_study_hours, math_score, history_score, physics_score,\n\u001b[0;32m     25\u001b[0m                            chemistry_score, biology_score, english_score, geography_score]])\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Scale features\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m scaled_features \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(feature_array)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Predict using the model\u001b[39;00m\n\u001b[0;32m     31\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(scaled_features)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    319\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:1043\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1040\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1042\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m-> 1043\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m   1044\u001b[0m     X,\n\u001b[0;32m   1045\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1046\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1047\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1048\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES,\n\u001b[0;32m   1049\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1050\u001b[0m )\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1053\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 654\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    446\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 12 features, but StandardScaler is expecting 14 features as input."
     ]
    }
   ],
   "source": [
    "final_recommendations = Recommendations(gender='female',\n",
    "                                        part_time_job=False,\n",
    "                                        absence_days=2,\n",
    "                                        extracurricular_activities=False,\n",
    "                                        weekly_self_study_hours=7,\n",
    "                                        math_score=65,\n",
    "                                        history_score=60,\n",
    "                                        physics_score=97,\n",
    "                                        chemistry_score=94,\n",
    "                                        biology_score=71,\n",
    "                                        english_score=81,\n",
    "                                        geography_score=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937f96d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
